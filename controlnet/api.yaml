Questions: 
- how to handle lists
- how to handle bools vs switch (on off)
- combo input
- should we use a preprocessor with controls?
- check naming
- model version
---

name: Controlnet
description: Use controlnet guidance with an input image to direct the shape of the composition 
tip: By using Canny to guide by Edge Detection, Midas for depth map estimation, or other controlnets such as scribble to guide by a crude line drawing, the composition of the image can be made to adhere to the shape of an input image, transferring the positioning to the output
output_type: image
handler: comfyui
comfyui_output_node_id: 2

parameters:
- name: positive
  label: Prompt
  description: Text prompt
  type: string
  required: true
  comfyui: 
    node_id: 1
    field: inputs
    subfield: text
- name: negative
  label: Negative prompt
  description: Negative text prompt, what you do *not* want to generate. You usually want to keep this at default or at most, add stuff to this prompt.
  type: string
  default: ugly, watermark, blurry, low-resolution, bad
  comfyui: 
    node_id: 1
    field: inputs
    subfield: text
# - name: model_version
#   label: model_version
#   description: choose the model version base we are employing, and set resolution variables based on this
#   type: string
#   default: SDXL 1024px
#   comfyui: 
#     node_id: 1
#     field: inputs
#     subfield: model version
- name: width
  label: Width
  description: Width in pixels
  type: int
  default: 1024
  minimum: 256
  maximum: 2048
  step: 8
  comfyui: 
    node_id: 1
    field: inputs
    subfield: width
- name: height
  label: Height
  description: Height in pixels
  type: int
  default: 512
  minimum: 256
  maximum: 2048
  step: 8
  comfyui: 
    node_id: 1
    field: inputs
    subfield: height
- name: seed
  label: Seed
  description: Set random seed for reproducibility. If blank, will be set to -1 to supply a random value.
  tip: You should only set this if you want to start from/copy the seed of a previous image. Unless one is specified, you should leave this blank! 
  type: int
  default: -1
  minimum: 0
  maximum: 10000000000000000
  comfyui: 
    node_id: 1
    field: inputs
    subfield: seed
# - name: lora
#   label: LoRA
#   description: Use a LoRA finetune on top of the base model.
#   type: lora
#   comfyui: 
#     node_id: 1
#     field: inputs
#     subfield: lora_name
# - name: lora_strength
#   label: LoRA strength
#   description: Strength of the LoRA
#   tip: If outputs resemble the LoRA but have low prompt adherence or all look the same, turn down the LoRA strength.
#   type: float
#   default: 0.5
#   comfyui: 
#     node_id: 1
#     field: inputs
#     subfield: strength_model, strength_clip
- name: init_image
  label: Starting image
  description: Initial image from which to start diffusion process
  type: image
  default: 0.000000_00000.jpg
  comfyui: 
    node_id: 28
    field: inputs
    subfield: image
- name: denoise
  label: Denoise strength
  description: Strength of denoising
  tip: Decreasing denoise strength increases the influence of the init image
  type: float
  default: 1.0
  comfyui: 
    node_id: 1
    field: inputs
    subfield: denoise
- name: steps
  label: Steps
  description: Length of diffusion steps
  tip: Increasing the steps increases the quality of the image with diminishing returns beyond 35, as well as the run time. Only change this if you want to experiment with 'undercooking' the image, or are using a specialized model.
  type: float
  default: 30
  comfyui: 
    node_id: 1
    field: inputs
    subfield: steps
- name: size_from_input
  label: Size From Input
  description: Override the width and height parameters with the actual resolution of your image. 
  tip: Its best practice to use resolutions included in the models training data. upscaling later can get you to a higher resolution
  type: bool
  default: true
  comfyui: 
    node_id: 1
    field: inputs
    subfield: size_from_input
- name: sdxl_aspect
  label: Aspect
  description: Override the width and height parameters with the best resolution closest to what the model was trained on. This will reduce artifacting and assist in a better image generation. 
  tip: SDXL was trained on images equaling about a megapixel, and generating within these preferred aspect ratios will produce better results
  type: bool
  default: true
  comfyui: 
    node_id: 1
    field: inputs
    subfield: sdxl_aspect
- name: input_img_is_controlnet
  label: Use init image for contolnet
  description: use the input image as the controlnet guidance image
  tip:  this will usually be true unless you want to mix guidance from a different image while using an init with denoise < 1.0
  type: bool  
  default: true
  comfyui: 
    node_id: 1
    field: inputs
    subfield: input_img_is_controlnet
- name: preprocessor
  label: Preprocessor
  description: the preprocessor you choose will prepare your input image to guide your diffusion towards that shape
  tip:  'depth_midas' will recreate the approximate depth of your input scene, and is best for 3 dimensional compositions. 'canny' creates strong edge adherance to the shape of your image, whereas 'scribble' will create guidance towards a rougher shape of your input image. 
  type: string
  default: canny
  choices: [canny, depth_midas, scribble, dwpose]
  comfyui: 
    node_id: 14
    field: inputs
    subfield: preprocessor_override
- name: switch
  label: ControlNet Active
  description: master toggle enabling controlnet stack
  tip:  leave on to use controlnet, toggle to 'Off' if controlnet guidance is not desired. do not use if no init image is provided
  type: string
  default: On
  comfyui: 
    node_id: 16
    field: inputs
    subfield: switch
- name: switch_1
  label: ControlNet1 Active
  description: enable or bypass the controlnet in slot 1
  tip:  toggle to off to bypass the slot 1 controlnet model in the stack
  type: string
  default: On
  comfyui: 
    node_id: 15
    field: inputs
    subfield: switch_1
- name: controlnet_strength_1
  label: Controlnet Strength 1
  description: set the guidance strength of the controlnet model in slot 1
  tip:  a good default is around 0.6, with ranges between 0.2 for subtle guidance, and 1.0 for something more heavy handed
  type: float
  default: .6
  comfyui: 
    node_id: 15
    field: inputs
    subfield: controlnet_strength_1
- name: extension
  label: file extension
  description: choose the format you'd like your results returned in
  tip:  .jpg is good unless otherwise required by the workflow, for instance background removal will require .png for alpha transparency
  type: string
  default: .jpg
  comfyui: 
    node_id: 2
    field: inputs
    subfield: extension

    