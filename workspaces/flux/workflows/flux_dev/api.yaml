name: Create an image (Advanced)
description: Generate an image from text using Flux.
tip: |-
  Flux is a text to image model that excels at prompt coherence and text generation. This should always be the default way to generate an image from text! Flux-dev can use ControlNet guidance to maintain the contours or shape outlines of the input image while generating a new style or aesthetic on top of it, and LoRA models to apply a pretrained fine tuned concept.
thumbnail: app/flux.png
cost_estimate: 2 * n_samples
output_type: image
resolutions: [21-9_1536x640, 16-9_1344x768, 3-2_1216x832, 4-3_1152x896, 1-1_1024x1024, 3-4_896x1152, 2-3_832x1216, 9-16_768x1344, 9-21_640x1536]
handler: comfyui
status: prod
base_model: flux_dev
comfyui_output_node_id: 206
parameters:
  prompt:
    type: str
    label: Prompt
    description: Describe an image
    tip: |-
      Flux loves very detailed and descriptive prompts so try to be elaborate. Flux is also great at drawing text in images so feel free to add something if it makes sense.
    required: true
    default: null
    comfyui:
      node_id: 131
      field: inputs
      subfield: value
  use_init_image:
    type: bool
    label: Use starting image
    description: Enable image-to-image, and controlnet guidance features
    tip: |-
      Using a starting image helps guide your prompted creation towards the colors present in your initial input. if an image is supplied with the prompt or controlnet is employed, this should be true.
    default: false
    comfyui:
      node_id: 145
      field: inputs
      subfield: value
  init_image:
    type: image
    label: Starting image
    description: Initial image from which to start diffusion process
    tip: |-
      This can be used to guide the image generation with colors and shapes of an input image. You typically want to use this with high denoise values >0.8 unless you only want very subtle variations of the starting image.
    visible_if: use_init_image=true
    comfyui:
      node_id: 302
      field: inputs
      subfield: image
  size_from_input:
    type: bool
    label: Use starting image size
    description: |-
      Override the width and height parameters with the actual resolution of your starting image.
    tip: |-
      It's best practice to use resolutions included in the models training data. Upscaling later can get you to a higher resolution.
    default: true
    visible_if: use_init_image=true
    comfyui:
      node_id: 120
      field: inputs
      subfield: value
  denoise:
    type: float
    label: Generation strength
    description: Strength of the generation process on top of the starting image
    tip: |-
      Decreasing generation strength increases the influence of a starting image in image-to-image workflows. The default of 1 is 100% AI creativity, ignoring all traces of the starting image, whereas a medium blend of about 50% will maintain close adherance to the original input.
    default: 1.0
    minimum: 0.0
    maximum: 1.0
    visible_if: use_init_image=true
    comfyui:
      node_id: 323
      field: inputs
      subfield: value
  use_lora:
    type: bool
    label: Use LoRA
    description: Apply LoRA finetune model style to image generation
    tip: |-
      Models created with Eden LoRA trainer can add people, styles and conceptual embeddings into the diffusion model, giving it an idea of new information provided by the user.
    default: false
    comfyui:
      node_id: 144
      field: inputs
      subfield: value
  lora:
    type: lora
    label: LoRA
    description: Use a LoRA finetune on top of the base model.
    visible_if: use_lora=true
    comfyui:
      node_id: 80
      field: inputs
      subfield: lora_name
  lora_strength:
    type: float
    label: LoRA Strength
    description: Strength of the LoRA
    tip: |-
      If outputs resemble the LoRA but have low prompt adherence or all look the same, turn down the LoRA strength.
    default: 0.6
    minimum: 0.0
    maximum: 1.5
    visible_if: use_lora=true
    comfyui:
      node_id: 141
      field: inputs
      subfield: value
  use_style_lora:
    type: bool
    label: Use Style LoRA
    description: |-
      Style LoRAs are handpicked third party flux loras trained by the opensource AI community
    tip: |-
      These optional LoRAs are hardcoded third party loras with specific functions, unlike the user trained loras from Eden.
    default: false
    comfyui:
      node_id: 339
      field: inputs
      subfield: value
  style_lora:
    type: str
    label: Style LoRA
    description: Use a LoRA finetune on top of the base model.
    visible_if: use_style_lora=true
    default: realism_lora_comfy_converted.safetensors
    choices: [realism_lora_comfy_converted.safetensors, mjv6_lora_comfy_converted.safetensors, art_lora_comfy_converted.safetensors]
    comfyui:
      node_id: 337
      field: inputs
      subfield: lora_name
  style_lora_strength:
    type: float
    label: LoRA Strength
    description: Strength of the LoRA
    tip: |-
      If outputs resemble the LoRA but have low prompt adherence or all look the same, turn down the LoRA strength.
    default: 0.6
    minimum: 0.0
    maximum: 1.5
    visible_if: use_style_lora=true
    comfyui:
      node_id: 338
      field: inputs
      subfield: value
  use_controlnet:
    type: bool
    label: Use controlnet
    description: |-
      Apply Controlnet guidance to the image generation (using the starting image as shape guidance).
    tip: Controlnet guides the generated output towards the shape of the Starting Image.
    default: false
    comfyui:
      node_id: 133
      field: inputs
      subfield: value
  preprocessor:
    type: str
    label: Controlnet preprocessor
    description: |-
      the preprocessor you choose will prepare your input image to guide your diffusion towards that shape
    tip: |-
      depth will recreate an approximate depth of your input scene, and is best for 3 dimensional compositions. Canny edge creates strong edge detection adherance to the shape of your image, whereas scribble will create subtle guidance towards a rougher sketched shape of your starting image.
    visible_if: use_controlnet=true
    default: CannyEdgePreprocessor
    choices: [CannyEdgePreprocessor, MiDaS-DepthMapPreprocessor, AnyLineArtPreprocessor_aux, HEDPreprocessor, DWPreprocessor, ScribblePreprocessor]
    choices_labels: [edges (canny), depth, lines (lineart), soft lines (HED), human pose, scribble]
    comfyui:
      node_id: 104
      field: inputs
      subfield: preprocessor
  controlnet_strength:
    type: float
    label: Controlnet strength
    description: set the guidance strength of the controlnet model in slot 1
    tip: |-
      A good default is around 0.6, with ranges between 0.2 for subtle guidance, and 1.0 for something more heavy handed
    default: 0.6
    minimum: 0.0
    maximum: 1.5
    visible_if: use_controlnet=true
    comfyui:
      node_id: 135
      field: inputs
      subfield: value
  width:
    type: int
    label: Width
    description: Width in pixels
    default: 1024
    minimum: 256
    maximum: 2048
    visible_if: use_init_image=false
    step: 8
    comfyui:
      node_id: 119
      field: inputs
      subfield: width
  height:
    type: int
    label: Height
    description: Height in pixels
    default: 1024
    minimum: 256
    maximum: 2048
    visible_if: use_init_image=false
    step: 8
    comfyui:
      node_id: 119
      field: inputs
      subfield: height
  seed:
    type: int
    label: Seed
    description: Set random seed for reproducibility. If blank, will be set to a random value.
    tip: |-
      You should only set this if you want to start from/copy the seed of a previous image. Unless one is specified, you should leave this blank!
    default: random
    minimum: 0
    maximum: 2147483647
    comfyui:
      node_id: 330
      field: inputs
      subfield: seed
  n_samples:
    type: int
    label: Number of samples
    description: Number of samples to generate
    tip: |-
      This is the number of tries to generate for the prompt. If you get a request for n_samples > 1, you are still using a *single* prompt for the whole set.
    default: 1
    minimum: 1
    maximum: 4
