name: Image Video Extension (LTX)
description: img-to-video, txt-to-video or movie extension using LTX
tip: |-
  This tool creates smooth transitions between two images using either LTXV (Lightricks Video).
  The LTXV model is optimized for shorter, medium-quality image generations and can be driven with text prompts and camera controls.
  txt2vid is not great yet, but I2V is where this shines.
  LTX is not as fancy as Kling or Runway tools, but its fast and is good for ideating for later upscale and processing.
  LTXV can also extend videos, but supplying a video input and enabling 
  LTXV works best shorter durations (2-8 seconds), but can go up to 16 seconds with frame interpolation halving the generation frames.
  Seed is an important parameter for getting different results from the same prompt.
  Use prompt enhancement for verbose LLM descriptions to get more creative results.
output_type: video
cost_estimate: '2 * duration_seconds * (resolution*1.5)/(2*640) * (frame_interpolation ? 1 : 2)'
thumbnail: app/ltxv_flow_edit_opt.mp4
status: staging
visible: false
active: false
#resolutions: [16-10_1120x640, 16-9_960x544, 3-2_768x512, 1-1_640x640, 2-3_512x768, 9-16_544x960, 10-16_640x1120]
handler: comfyui
base_model: ltxv
comfyui_output_node_id: 813
parameters:
  input:
    anyOf:
    - type: image
    - type: video
    label: Input
    description: |-
      input image or video to extend with movie generation.
      if an input video is provided, the last frame will be used as the first frame of the video extension.
    required: true
    comfyui:
      node_id: 1056
      field: inputs
      subfield: path
  duration_seconds:
    type: float
    label: Duration (seconds)
    description: Length of the transition in seconds
    tip: |-
      The duration of the image to video generation.
      The default is 4 seconds. beyond 8 seconds frame interpolation is recommended.
    default: 4.0
    minimum: 2.0
    maximum: 32.0
    step: 0.5
    required: true
    comfyui:
      node_id: 1007
      field: inputs
      subfield: value
  resolution:
    type: integer
    label: Resolution (longest side)
    description: Output video resolution will maintain aspect of input media limited to this value
    tip: |-
      The output video will be scaled to this resolution, with speed tradeoffs at higher resolutions.
      Set the resolution to the longest side of your input media to maintain a consistent scale.
      Best practice is to use media of the same size to avoid scaling artifacts.
    default: 960
    minimum: 640
    maximum: 1280
    step: 32
    required: true
    comfyui:
      node_id: 1008
      field: inputs 
      subfield: value
  prompt:
    type: string
    label: Video Generation Prompt
    description: Describe the scene you want to create
    default: ""
    required: true
    comfyui:
      node_id: 1014
      field: inputs
      subfield: value
  use_prompt_enhance:
    type: boolean
    label: Enhance Prompt
    description: Use AI vision model to enhance the transition prompt for detailed results
    tip: |-
      Use prompt enhancement for verbose LLM descriptions to get more creative results.
      This will help expand your prompt to fill a target token count preferred by the model.
      While often producing more creative results, it can also produce more hallucinations.
      the prompt prefix text will be prepended unaltered to the result of prompt enhancement for explicit control.
    default: true
    comfyui:
      node_id: 222
      field: inputs
      subfield: boolean
  frame_interpolation:
    type: boolean
    label: Enable Frame Interpolation
    description: Use RIFE to generate additional frames for smoother motion
    tip: |-
      This will halve the the number of inference frames generated, enabling longer outputs.
      This is recommended for longer durations (4-16 seconds).
    default: false
    comfyui:
      node_id: 1026
      field: inputs
      subfield: value
  seed:
    type: integer
    label: Seed
    description: Set the seed for reproducible results. 
    tip: |-
      Seed is an important parameter for getting different results from the same prompt or input images.
      If you're unhappy with resutls, try a few more generations for different variations.
    default: random
    minimum: 0
    maximum: 2147483647
    comfyui:
      node_id: 910
      field: inputs
      subfield: seed
  fps:
    type: integer
    label: FPS
    description: Frames per second for the output video
    default: 24
    minimum: 8
    maximum: 30
    step: 1 
    hide_from_ui: true
    hide_from_agent: true
    comfyui:
      node_id: 979
      field: inputs
      subfield: value
  use_camera:
    type: boolean
    label: Use Camera Motion
    description: Enable advanced WanVideo model parameters for fine-tuning
    default: false
    comfyui:
      node_id: 967
      field: inputs
      subfield: value
  camera_mode:
    type: string
    label: Camera Mode
    description: Determines the type of camera motion applied through depth flow edit
    tip: select a motion guidance mode to direct camera movement
    default: Zoom In
    choices: [static, Zoom In, Zoom Out, left pan, right pan, up, down, Orbit Horizontal Right, Orbit Horizontal Left, Orbit Vertical Low, Orbit Vertical High]
    choices_labels: [static, Zoom In, Zoom Out, left pan, right pan, up, down, Orbit Horizontal Right, Orbit Horizontal Left, Orbit Vertical Low, Orbit Vertical High]
    visible_if: use_camera=true
    comfyui:
      node_id: 961
      field: inputs
      subfield: select_item
  camera_steps:
    type: integer
    label: Camera Steps
    description: Sets the initial vector for camera movement. 
    tip: |-
      Use 2 steps. 0 steps is off.
      If camera doesn't move as desired, try another seed and/or increase steps.
    default: 2
    minimum: 0
    maximum: 4
    visible_if: use_camera=true
    comfyui:
      node_id: 958
      field: inputs
      subfield: value
  frate:
    type: float
    label: Frate
    description: Frame rate for the guidance video
    tip: high values give more motion.
    default: 5.00
    minimum: 5.00
    maximum: 25.00
    step: 0.1
    visible_if: use_camera=true
    hide_from_ui: true
    hide_from_agent: true
    comfyui:
      node_id: 941
      field: inputs
      subfield: value
  max_input_frames:
    type: integer
    label: Max Input Frames
    description: Maximum number of frames to use for input
    default: 384
    minimum: 1
    maximum: 384
    step: 12
    visible_if: use_camera=true
    comfyui:
      node_id: 1065
      field: inputs
      subfield: value
  crf:
    type: integer
    label: CRF
    description: guidance quality compression
    tip: compression, high values give more motion and lower the output quality.
    default: 25
    minimum: 10
    maximum: 30
    visible_if: use_advanced_parameters=true
    comfyui:
      node_id: 939
      field: inputs
      subfield: value
  use_advanced_parameters:
    type: boolean
    label: Advanced Parameters
    description: Enable advanced WanVideo model parameters for fine-tuning
    default: false
    comfyui:
      node_id: 1032
      field: inputs
      subfield: value
  negative_prompt:
    type: string
    label: Negative Prompt
    description: A prompt that describes what should not be in the output video
    default: "worst quality, inconsistent motion, blurry, jittery, distorted, watermarks, text, title, watermark, shaky, glitchy, low quality, deformed, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly"
    comfyui:
      node_id: 1033
      field: inputs
      subfield: value
  cfg:
    type: float
    label: CFG
    description: Control the strength of the prompt in the generation
    tip: lower values give more motion, high values give less motion and overcooked look.
    default: 3
    minimum: 1
    maximum: 7
    visible_if: use_advanced_parameters=true
    comfyui:
      node_id: 939
      field: inputs
      subfield: value
  steps:
    type: integer
    label: Steps
    description: Number of diffusion steps for the output video
    tip: |-
      22 to 28 steps is a good default for most use cases for the dev model
      8 to 22 steps is a good default for most use cases for the distilled model
    default: 22
    minimum: 8
    maximum: 28
    visible_if: use_advanced_parameters=true
    comfyui:
      node_id: 955
      field: inputs
      subfield: value
  model:
    type: string
    label: SDXL Model
    description: Pick which SDXL model to use
    tip: |-
      The ltxv-2b-0.9.6-dev-04-25.safetensors model is the latest and most powerful model
      22 steps is a good default for most use cases for the dev model
      You can do faster distilled model generations with as few as 8 steps with a speed quality tradeoff. 
    default: ltxv-2b-0.9.6-dev-04-25.safetensors
    choices: [ltxv-2b-0.9.6-dev-04-25.safetensors, ltxv-2b-0.9.6-distilled-04-25.safetensors]
    visible_if: use_advanced_parameters=true
    comfyui:
      node_id: 227
      field: inputs
      subfield: ckpt_name
