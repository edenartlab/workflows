{
  "1": {
    "inputs": {
      "image": "black_dummy.jpg",
      "upload": "image"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "2": {
    "inputs": {
      "ckpt_name": "juggernaut_reborn.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "3": {
    "inputs": {
      "lora_name": "more_details.safetensors",
      "strength_model": 0.25,
      "strength_clip": 0.25,
      "model": [
        "2",
        0
      ],
      "clip": [
        "2",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "4": {
    "inputs": {
      "lora_name": "SDXLrender_v2.0.safetensors",
      "strength_model": 0.1,
      "strength_clip": 0.1,
      "model": [
        "3",
        0
      ],
      "clip": [
        "2",
        1
      ]
    },
    "class_type": "LoraLoader",
    "_meta": {
      "title": "Load LoRA"
    }
  },
  "5": {
    "inputs": {
      "text": "masterpiece, best quality, highres",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "6": {
    "inputs": {
      "text": "(worst quality, low quality, normal quality:1.5)",
      "clip": [
        "4",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "model_name": "4xNomosUniDAT_otf.safetensors"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "8": {
    "inputs": {
      "upscale_model": [
        "7",
        0
      ],
      "image": [
        "46",
        0
      ]
    },
    "class_type": "ImageUpscaleWithModel",
    "_meta": {
      "title": "Upscale Image (using Model)"
    }
  },
  "9": {
    "inputs": {
      "upscale_method": "lanczos",
      "image": [
        "8",
        0
      ]
    },
    "class_type": "ImageScaleBy",
    "_meta": {
      "title": "Upscale Image By"
    }
  },
  "12": {
    "inputs": {
      "tile_size": 1024,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "pixels": [
        "85",
        0
      ],
      "vae": [
        "2",
        2
      ]
    },
    "class_type": "VAEEncodeTiled",
    "_meta": {
      "title": "VAE Encode (Tiled)"
    }
  },
  "13": {
    "inputs": {
      "b1": 1.05,
      "b2": 1.08,
      "s1": 0.9500000000000001,
      "s2": 0.8,
      "model": [
        "4",
        0
      ]
    },
    "class_type": "FreeU_V2",
    "_meta": {
      "title": "FreeU_V2"
    }
  },
  "14": {
    "inputs": {
      "scale": 1,
      "model": [
        "13",
        0
      ]
    },
    "class_type": "PerturbedAttentionGuidance",
    "_meta": {
      "title": "PerturbedAttentionGuidance"
    }
  },
  "15": {
    "inputs": {
      "hard_mode": true,
      "boost": true,
      "model": [
        "14",
        0
      ]
    },
    "class_type": "Automatic CFG",
    "_meta": {
      "title": "Automatic CFG"
    }
  },
  "16": {
    "inputs": {
      "method": "MultiDiffusion",
      "tile_width": 1024,
      "tile_height": 1024,
      "tile_overlap": 128,
      "tile_batch_size": 4,
      "model": [
        "15",
        0
      ]
    },
    "class_type": "TiledDiffusion",
    "_meta": {
      "title": "Tiled Diffusion"
    }
  },
  "17": {
    "inputs": {
      "control_net_name": "control_v11f1e_sd15_tile_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "18": {
    "inputs": {
      "strength": 0.5,
      "start_percent": 0,
      "end_percent": 1,
      "positive": [
        "5",
        0
      ],
      "negative": [
        "6",
        0
      ],
      "control_net": [
        "17",
        0
      ],
      "image": [
        "46",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "20": {
    "inputs": {
      "sampler_name": "dpmpp_3m_sde_gpu"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "21": {
    "inputs": {
      "model_type": "SD1",
      "steps": 25,
      "denoise": 0.35000000000000003
    },
    "class_type": "AlignYourStepsScheduler",
    "_meta": {
      "title": "AlignYourStepsScheduler"
    }
  },
  "25": {
    "inputs": {
      "add_noise": true,
      "noise_seed": 5398475983,
      "cfg": 8,
      "model": [
        "107",
        0
      ],
      "positive": [
        "18",
        0
      ],
      "negative": [
        "18",
        1
      ],
      "sampler": [
        "20",
        0
      ],
      "sigmas": [
        "21",
        0
      ],
      "latent_image": [
        "12",
        0
      ]
    },
    "class_type": "SamplerCustom",
    "_meta": {
      "title": "SamplerCustom"
    }
  },
  "26": {
    "inputs": {
      "tile_size": 1024,
      "overlap": 64,
      "temporal_size": 64,
      "temporal_overlap": 8,
      "samples": [
        "25",
        0
      ],
      "vae": [
        "2",
        2
      ]
    },
    "class_type": "VAEDecodeTiled",
    "_meta": {
      "title": "VAE Decode (Tiled)"
    }
  },
  "46": {
    "inputs": {
      "width": 2048,
      "height": 2048,
      "interpolation": "nearest",
      "method": "keep proportion",
      "condition": "downscale if bigger",
      "multiple_of": 0,
      "image": [
        "1",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize_clamp maximum"
    }
  },
  "63": {
    "inputs": {
      "filename_prefix": "upscaled",
      "add_timestamp": true,
      "save_metadata_json": false,
      "images": [
        "105",
        0
      ]
    },
    "class_type": "SaveImageAdvanced",
    "_meta": {
      "title": "SaveImageAdvanced"
    }
  },
  "85": {
    "inputs": {
      "width": [
        "86",
        0
      ],
      "height": [
        "86",
        0
      ],
      "interpolation": "lanczos",
      "method": "keep proportion",
      "condition": "always",
      "multiple_of": 8,
      "image": [
        "8",
        0
      ]
    },
    "class_type": "ImageResize+",
    "_meta": {
      "title": "ðŸ”§ Image Resize"
    }
  },
  "86": {
    "inputs": {
      "value": 2048
    },
    "class_type": "Eden_Int",
    "_meta": {
      "title": "LONGEST SIDE"
    }
  },
  "87": {
    "inputs": {
      "image": [
        "1",
        0
      ]
    },
    "class_type": "Get resolution [Crystools]",
    "_meta": {
      "title": "ðŸª› Get resolution"
    }
  },
  "89": {
    "inputs": {
      "preset": "PLUS (high strength)",
      "model": [
        "16",
        0
      ]
    },
    "class_type": "IPAdapterUnifiedLoader",
    "_meta": {
      "title": "IPAdapter Unified Loader"
    }
  },
  "90": {
    "inputs": {
      "interpolation": "LANCZOS",
      "crop_position": "center",
      "sharpening": 0.05,
      "image": [
        "85",
        0
      ]
    },
    "class_type": "PrepImageForClipVision",
    "_meta": {
      "title": "Prep Image For ClipVision"
    }
  },
  "92": {
    "inputs": {
      "weight": [
        "95",
        0
      ],
      "weight_type": "ease in-out",
      "combine_embeds": "concat",
      "start_at": 0,
      "end_at": 1,
      "embeds_scaling": "V only",
      "enhance_tiles": 2,
      "enhance_ratio": 1,
      "model": [
        "89",
        0
      ],
      "ipadapter": [
        "89",
        1
      ],
      "image": [
        "90",
        0
      ]
    },
    "class_type": "IPAdapterClipVisionEnhancer",
    "_meta": {
      "title": "IPAdapter ClipVision Enhancer"
    }
  },
  "93": {
    "inputs": {
      "color_space": "LAB",
      "factor": 1,
      "device": "auto",
      "batch_size": 0,
      "image": [
        "26",
        0
      ],
      "reference": [
        "85",
        0
      ]
    },
    "class_type": "ImageColorMatch+",
    "_meta": {
      "title": "ðŸ”§ Image Color Match"
    }
  },
  "95": {
    "inputs": {
      "value": 0.75
    },
    "class_type": "Eden_Float",
    "_meta": {
      "title": "IPADAPTER STRENGTH"
    }
  },
  "97": {
    "inputs": {
      "value": true
    },
    "class_type": "Eden_Bool",
    "_meta": {
      "title": "USE IPADAPTER"
    }
  },
  "99": {
    "inputs": {
      "value": false
    },
    "class_type": "Eden_Bool",
    "_meta": {
      "title": "USE COLOR MATCH"
    }
  },
  "101": {
    "inputs": {
      "text": "[1,2][%aux%]",
      "output_type": "ANY"
    },
    "class_type": "DataMonitor",
    "_meta": {
      "title": "bool to int"
    }
  },
  "102": {
    "inputs": {
      "text": "[1,2][%aux%]",
      "output_type": "FORMULA",
      "aux": [
        "99",
        0
      ]
    },
    "class_type": "DataMonitor",
    "_meta": {
      "title": "bool to int"
    }
  },
  "105": {
    "inputs": {
      "mode": "SWITCH",
      "selection_in": [
        "102",
        0
      ],
      "selection_out": 1,
      "validate_typing": false,
      "input1": [
        "26",
        0
      ],
      "input2": [
        "93",
        0
      ]
    },
    "class_type": "UniversalSwitch",
    "_meta": {
      "title": "ðŸ’  Universal Switch"
    }
  },
  "106": {
    "inputs": {
      "text": "[1,2][%aux%]",
      "output_type": "FORMULA",
      "aux": [
        "97",
        0
      ]
    },
    "class_type": "DataMonitor",
    "_meta": {
      "title": "bool to int"
    }
  },
  "107": {
    "inputs": {
      "mode": "SWITCH",
      "selection_in": [
        "106",
        0
      ],
      "selection_out": 1,
      "validate_typing": false,
      "input1": [
        "16",
        0
      ],
      "input2": [
        "92",
        0
      ]
    },
    "class_type": "UniversalSwitch",
    "_meta": {
      "title": "ðŸ’  Universal Switch"
    }
  }
}